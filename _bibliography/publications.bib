---
---
References
==========

@inproceedings{shuo:2023:iros,
  author      = {Sun, Shuo and Chen, Jie and Sun, Jiawei and Yuan, Chengran and Li, Yuanchen and Zhang, Tangyike and Ang, Marcelo H.},
  title       = {FISS+: Efficient and Focused Trajectory Generation and Refinement using Fast Iterative Search and Sampling Strategy},
  booktitle   = {The 2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2023)},
  year        = {2023},
  month       = {Oct},
  abstract    = {Trajectory planning plays a crucial role in autonomous driving systems, as it is tasked to generate feasible trajectories under highly dynamic scenarios within the time constraint. This paper proposes a novel two-stage coarse-to-fine framework for efficient sampling-based trajectory planning. The proposed method is designed to iteratively generate new trajectory samples focused on the low-cost regions in the sampling space. Two trajectory exploration algorithms are well-designed for efficient search in discretized coarse global space and continuous fine local space, respectively. Experimental results on the first-of-its-kind planning benchmark tool CommonRoad show that our method significantly outperforms the baseline methods both in optimality and computational efficiency. Overall, our approach offers a promising solution for efficient and effective trajectory planning in more autonomous vehicle applications. },
  bibtex_show = true
}

@inproceedings{tangyike:2023:itsc,
  author      = {Zhang, Tangyike and Sun, Shuo and Shi, Jiamin and Chen, Shitao and Ang, Marcelo H. and Xin, Jingmin and Zheng, Nanning},
  title       = {Maximum Entropy Inverse Reinforcement Learning Based on Frenet Frame Sampling for Human-like Autonomous Driving},
  booktitle   = {2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC 2023)},
  year        = {2023},
  month       = {Sep},
  abstract    = {Ensuring social acceptability is a key factor in the successful operation of autonomous vehicles. To achieve this, it is important to extract driving habits from expert human drivers. This paper proposes a maximum entropy inverse reinforcement learning method based on Frenet frame sampling for reward function learning. The proposed method is applied to learn the reward function of human drivers’ lane- changing and velocity-keeping actions in multi-lane scenarios from the nuPlan dataset, which achieves better performance than traditional Cartesian frame sampling-based methods. By converting the reward value of each sample into a probability distribution in the sample space, a convex space with human driving characteristics can be provided for the lower-level trajectory planner. These improvements make autonomous vehicles tend to choose trajectories that are more in line with human driving habits. Experimental results demonstrate that the learned reward function can effectively characterize human drivers’ tendencies for multiple optimization metrics in multi- lane scenarios and exhibit strong interpretability. Under test conditions, the learned reward function can more effectively characterize human driving behavior and habits.},
  bibtex_show = true
}

@inproceedings{jiawei:2023:cisram,
  author      = {Sun, Jiawei and Liu, Tingchen and Yuan, Chengran and Sun, Shuo and Yong, Anthony and Tee, Keng Peng and Ang, Marcelo H.},
  title       = {An Adaptive Local Context Extraction Method for Motion Prediction and Planning},
  booktitle   = {The 10th IEEE International Conference on Cybernetics and Intelligent Systems, and Robotics, Automation and Mechatronics (CIS-RAM 2023)},
  year        = {2023},
  month       = {Jun},
  abstract    = {Learning-based motion prediction and planning algorithms can efficiently extract and effectively represent the agent-map relationships in high-dimensional space. Generally, the performance is highly related to the neural network structure and quality of input data. However, existing works are more focused on exploring novel network structures while ignoring the form of data input. Typically, for a target agent to predict or plan, they simply input all road polylines within its $R$-meters radius as local context information and then use a network such as a cross-attention module to filter out the unimportant and irrelevant part of the local context. This simple strategy not only burdens the network in spatial and temporal computation consumption but also leads to much redundancy and overlapping when two target agents are very close. We propose our Adaptive Breadth-First Search (ABFS) local context extraction method to tackle these issues. ABFS inherits from breadth-first search (BFS), adding adaptive search depth based on the agent's current state and changing the weights of the search direction (more focused on the roads forward). We compare our methods with previous radius search (RS) based  and depth-first search (DFS) based context extraction methods. Systematic experiments are done based on the Differentiable Integrated Motion Prediction and Planning (DIPP) algorithm using Waymo motion dataset. We give both qualitative and quantitative results to show our method's superiority.},
  bibtex_show = true
}

@misc{jiawei:2023:icccr,
  author      = {Jiawei Sun and Chengran Yuan and Shuo Sun and Zhiyang Liu and Terence Goh and Anthony Wong and Keng Peng Tee and Marcelo H. Ang Jr},
  title       = {GET-DIPP: Graph-Embedded Transformer for Differentiable Integrated Prediction and Planning},
  year        = {2022},
  month       = {Nov},
  arxiv       = {arXiv:2211.06031},
  doi         = {https://doi.org/10.48550/arXiv.2211.06031},
  html        = {https://arxiv.org/abs/2211.06031},
  pdf         = {https://arxiv.org/pdf/2211.06031.pdf},
  abstract    = {Accurately predicting interactive road agents' future trajectories and planning a socially compliant and human-like trajectory accordingly are important for autonomous vehicles. In this paper, we propose a planning-centric prediction neural network, which takes surrounding agents' historical states and map context information as input, and outputs the joint multi-modal prediction trajectories for surrounding agents, as well as a sequence of control commands for the ego vehicle by imitation learning. An agent-agent interaction module along the time axis is proposed in our network architecture to better comprehend the relationship among all the other intelligent agents on the road. To incorporate the map's topological information, a Dynamic Graph Convolutional Neural Network (DGCNN) is employed to process the road network topology. Besides, the whole architecture can serve as a backbone for the Differentiable Integrated motion Prediction with Planning (DIPP) method by providing accurate prediction results and initial planning commands. Experiments are conducted on real-world datasets to demonstrate the improvements made by our proposed method in both planning and prediction accuracy compared to the previous state-of-the-art methods.},
  bibtex_show = true
}

@inproceedings{shuo:2022:icarcv,
  author      = {Sun, Shuo and Zhang, Tangyike and Xiang, Zhihai and Han, Yuhang and Li, Dongen and Li, Jianghao and Liu, Zhiyang and Ang, Marcelo H.},
  title       = {Autonomous Research Platform for Cleaning Operations in Mixed Indoor & Outdoor Environments},
  booktitle   = {The 17th International Conference on Control, Automation, Robotics and Vision (ICARCV 2022)},
  year        = {2022},
  month       = {Dec},
  abstract    = {In recent years, following the advances in autonomous driving technology, low-speed autonomous service vehicles such as delivery, patrolling, and road-cleaning vehicles have started to emerge. As a promising future cleaning solution, autonomous cleaning vehicles are expected to address the workforce shortage many countries face in the near future. This paper describes the detailed design of an autonomous research platform for cleaning operations in mixed indoor \& outdoor environments. An electric manual vacuum sweeper is retrofitted into an autonomous sweeper equipped with the Drive-by-Wire (DBW) system, computer, sensors, and actuators essential for autonomous driving. A complete autonomous driving software stack is also developed upon this hardware setup to enable the vehicle to navigate itself safely in various challenging operating environments. The system has been extensively tested in different environments on the National University of Singapore (NUS) campus, including private roads, car parks, warehouses, and public plaza areas.},
  bibtex_show = true
}

@inproceedings{yifan:2022:itsc,
  author      = {Chen, Yifan and Sun, Shuo and Yin, Huan and Ang, Marcelo H.},
  booktitle   = {2022 IEEE 25th International Conference on Intelligent Transportation Systems (ITSC 2022)},
  title       = {Exploring the Effect of 3D Object Removal using Deep Learning for LiDAR-based Mapping and Long-term Vehicular Localization},
  year        = {2022},
  month       = {Oct},
  publisher   = {IEEE},
  pages       = {1730-1735},
  doi         = {10.1109/ITSC55140.2022.9921969},
  html        = {https://ieeexplore.ieee.org/document/9921969},
  pdf         = {https://ieeexplore.ieee.org/document/9921969},
  abstract    = {The construction of a 3D point cloud map for long-term vehicle localization has always been a challenge in the autonomous driving community. In a highly dynamic urban environment, Simultaneous Localization and Mapping (SLAM) systems can be heavily affected by non-permanent objects and features during the mapping process, leaving undesired noise in the final map, which is redundant for long-term application. This paper explores applying object detection neural networks in SLAM systems to reduce the effect of dynamic objects (e.g., vehicles, pedestrians, cyclists). Specifically, we use PointPillars to detect and remove objects first and then perform LOAM to achieve a more static mapping. In the experimental section, the proposed method is validated on the public KITTI Odometry dataset. Compared with the original LOAM, the proposed method can provide a static point cloud map, thus improving the robustness of long-term vehicle applications.},
  bibtex_show = true
}

@article{shuo:2022:ral,
  abbr        = {FISS},
  author      = {Sun, Shuo and Liu, Zhiyang and Yin, Huan and Ang, Marcelo H.},
  journal     = {IEEE Robotics and Automation Letters (RA-L 2022)},
  title       = {FISS: A Trajectory Planning Framework Using Fast Iterative Search and Sampling Strategy for Autonomous Driving},
  year        = {2022},
  volume      = {7},
  number      = {4},
  pages       = {9985-9992},
  abstract    = {Trajectory planning is a critical component in autonomous vehicles directly responsible for driving safety and efficiency during deployment. The ability to find the optimal trajectory in real-time is critical for autonomous driving. This paper presents a novel general framework using the Fast Iterative Search and Sampling (FISS) strategy for sampling-based trajectory planning, which can find the optimal trajectory from an enormous number of candidates with high efficiency in real-time. Specifically, before generating any trajectories, the proposed method utilizes historical planning results as prior information in heuristics to estimate the cost distribution over the sampling space. On this basis, the Fast Iterative Search and Sampling strategy is employed to explore the sampling space for possible candidates and generate trajectories for verification during the search process. Experimental results show that our method can significantly outperform existing frameworks by order of magnitude in planning efficiency while ensuring safety and maintaining high accuracy.},
  keywords    = {Motion and path planning, autonomous vehicle navigation, intelligent transportation systems},
  doi         = {10.1109/LRA.2022.3191940},
  ISSN        = {2377-3766},
  month       = {Oct},
  code        = {https://github.com/SS47816/fiss_planner},
  slides      = {https://youtu.be/jzRzVJsofPU},
  html        = {https://ieeexplore.ieee.org/document/9833251},
  pdf         = {https://ieeexplore.ieee.org/document/9833251},
  bibtex_show = true
}

arxiv       = {2207.09703},
url         = {https://www.google.com},
poster      = {https://www.google.com},
supp        = {https://www.google.com},
blog        = {https://www.google.com},
website     = {https://www.google.com},
latex_src   = {https://www.google.com},